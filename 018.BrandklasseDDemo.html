<!DOCTYPE html>
<html lang="en">
  <head>
    <title>BrandklasseDDemo</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=no"
    />
    <link type="text/css" rel="stylesheet" href="style.css" />
    <script
      src="https://unpkg.com/three@0.133.0/build/three.js"
      crossorigin="anonymous"
    ></script>
    <script src="https://unpkg.com/three@0.133.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="//cdn.jsdelivr.net/npm/eruda"></script>
  </head>

  <body>
    <div id="console-ui"></div>
    <script type="module">
      setupMobileDebug();
      // Dieses Beispiel ist für Android Smartphones konzipiert; iOS soll noch folgen.

      import { ARButton } from "https://unpkg.com/three@0.133.0/examples/jsm/webxr/ARButton.js";

      let camera, scene, renderer;
      let mesh;
      let image;
      let loader; // Hier wird eine Variable erstellt, um später ein glb Model laden zu können.
      let model; // Speichermöglichkeit des Models.

      init();
      animate();
      
      function setupMobileDebug() {
      // Dieses Codestück ermöglicht es , mit einem Android Smartphone aktiv zu debuggen(Konsole); sehr wichtig.
      // Diese Bibliothek ist sehr groß, dies wird während des Debuggens deutlich (lange Laufzeit).
        const containerEl = document.getElementById("console-ui");
        eruda.init({
          container: containerEl
        });
        const devToolEl = containerEl.shadowRoot.querySelector('.eruda-dev-tools');
        devToolEl.style.height = '40%'; // Mit diesem Wert kontrolliert man die Höhe des dev tool Feldes.
      }

      async function init() {
        const container = document.createElement("div");
        document.body.appendChild(container);

        scene = new THREE.Scene();

        camera = new THREE.PerspectiveCamera(
          70,
          window.innerWidth / window.innerHeight,
          0.01,
          40
        );

        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;
        container.appendChild(renderer.domElement);

        const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
        light.position.set(0.5, 1, 0.25);
        scene.add(light);

        await loadModel();

        // An dieser Stelle wird das Image_Target eingerichtet. Ob ein Bild tauglich ist als Image_Target, kann mit vuforia überprüft werden. Dieses Bild erhielt 4 von 5 Sternen.
        const url =
          "https://cdn.glitch.global/84c4dc6d-1083-4fb6-b419-048dbca3be71/brandklasse_d%20(1).jpg?v=1687351859575";
        const imgBitmap = await getImageBitmap(url);

        const button = ARButton.createButton(renderer, {
          requiredFeatures: ["image-tracking"], // Dieses Feature muss explizit freigeschaltet werden.
          trackedImages: [
            {
              image: imgBitmap, // Mit dieser Zeile teilen wir webxr mit, dass dies das Image_Target ist, dass wir tracken wollen.
              widthInMeters: 0.7,
            },
          ],
          optionalFeatures: ["dom-overlay", "dom-overlay-for-handheld-ar"], // dadurch wird das Debugging angezeigt.
          domOverlay: {
            root: document.body
          }
        });
        document.body.appendChild(button);

        window.addEventListener("resize", onWindowResize, false);
      }
      
      // Das Model, also das Bild ,dass auf dem Image_Target erscheinen soll, wird hier der Szene hinzugefügt.
      async function loadModel() {
        const modelUrl =
          "https://cdn.glitch.global/84c4dc6d-1083-4fb6-b419-048dbca3be71/scene(38).glb?v=1687421190946";

        const loader = new THREE.GLTFLoader();
        
        const gltf = await loader.loadAsync(modelUrl); 
        model = gltf.scene; // An dieser Stelle kann ein Bezug des Models gespeichert werden.
        
        // model.matrixAutoUpdate = false;
        model.scale.multiplyScalar(-2);
        model.visible = false; // das Model soll anfangs nicht sichtbar sein, erst nachdem das Image_Target erkannt worden ist.
        
        
        scene.add(model);
      }

      function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();

        renderer.setSize(window.innerWidth, window.innerHeight);
      }

      function animate() {
        renderer.setAnimationLoop(render);
      }

      async function getImageBitmap(url) {
        const response = await fetch(url);
        const blob = await response.blob();
        const imageBitmap = await createImageBitmap(blob);
        return imageBitmap;
      }

      // optional: Ein Kegel Gebilde (Mesh) wird upgedated, sobald das Image_Target erfolgreich erkannt worden ist. (Kann im Debug Modus nachvollzogen werden).
      // Sollte der Kegel erscheinen bedeutet dies, dass die Position des Models, das erscheinen soll, nicht stimmt.
      function updateMesh(pose) {
        if (model) {
          model.rotation.x = pose.transform.orientation.x;
          model.rotation.y = pose.transform.orientation.y;
          model.rotation.z = pose.transform.orientation.z;
          
          model.position.x = pose.transform.position.x;
          model.position.y = pose.transform.position.y;
          model.position.z = pose.transform.position.z;
        }
      }

      function render(timestamp, frame) {
        if (frame) {
          const results = frame.getImageTrackingResults();

          for (const result of results) {
            // Im Result Index ist die Position des Image_Targets in einem Array aus potentiell mehreren Image_Targets hinterlegt. Da hier nur ein Image_Target vorhanden ist, erhält dieses standardmäßig den Wert 0. (und nicht 1).
            const imageIndex = result.index;

            // Erhalte die Darstellung des Modells bezogen auf eine Bezugsfläche.
            const referenceSpace = renderer.xr.getReferenceSpace();
            const pose = frame.getPose(result.imageSpace, referenceSpace);

            const state = result.trackingState;

            if (state == "tracked") {
              // In der Konsole wird angezeigt, sobald das Image_Target als solches erkannt worden ist.
               console.log("Image target has been found");
              if (model) {
                model.visible = true;
                updateMesh(pose);
              }
            } else if (state == "emulated") {
              // Weiterhin wird angezeigt, wenn das Image_Target nicht mehr als solches erkannt wird.
              if (model) {
                model.visible = false;
              }
               console.log("Image target no longer seen");
            }
          }
        }
        renderer.render(scene, camera);
      }
    </script>
  </body>
</html>
